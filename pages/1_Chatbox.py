import streamlit as st
from langchain.memory import ConversationBufferMemory
from utils import get_chat_response

st.set_page_config(layout="centered")
st.title("ğŸ’¬ èŠå¤©å°åŠ©æ‰‹ChatMate AI")
# Initialize or retrieve the selected model from session state
if 'selected_model' not in st.session_state:
    st.session_state['selected_model'] = 'gemini'  # Default model

with st.expander("è¯·é€‰æ‹©ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹ Please choose the language model you'd like to useï¼š"):
    proposed_model = st.radio("", ["gpt-3.5", "gemini"], 
                            index=["gpt-3.5", "gemini"].index(st.session_state['selected_model']))
    if st.button('é€‰æ‹© Select'):
        st.session_state['selected_model'] = proposed_model  # Update the session state only when button is clicked

st.write("å½“å‰é€‰æ‹©çš„æ¨¡å‹æ˜¯ The selected model isï¼š", st.session_state['selected_model'])

if "memory" not in st.session_state:
    st.session_state["memory"] = ConversationBufferMemory(return_messages=True)
    st.session_state["messages"] = [{"role": "ai",
                                     "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼ŸHey there! I'm your AI assistant. What can I help you with today?"}]

for message in st.session_state["messages"]:
    st.chat_message(message["role"]).write(message["content"])

prompt = st.chat_input()
if prompt:
    
    st.session_state["messages"].append({"role": "human", "content": prompt})
    st.chat_message("human").write(prompt)

    with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰...Your AI assistant is working..."):
        response = get_chat_response(prompt, st.session_state["memory"], st.session_state['selected_model'])
    msg = {"role": "ai", "content": response}
    st.session_state["messages"].append(msg)
    st.chat_message("ai").write(response)